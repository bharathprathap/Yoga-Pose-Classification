{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Phase-2-models_for_comparison[other_than_efficientnet].ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ8Ob9QAL1rD"
      },
      "source": [
        "# **YOGA POSE CLASSIFICATION [COMPARING WITH OTHER MODELS]**\n",
        "\n",
        "BY\n",
        "\n",
        "        Anand K S [AM.EN.U4CSE19106]\n",
        "        Bharath Prathap Nair [AM.EN.U4CSE19113]\n",
        "        Rahan Manoj [AM.EN.U4CSE19144]\n",
        "\n",
        "This notebook contains the code used to generate various CNN architectures that are then compared with the efficient net architecture.\n",
        "\n",
        "The Codes used while implementing these different architectures are given in this notebook.\n",
        "\n",
        "The dataset used in this notebook is taken from [Kaggle](www.kaggle.com/shrutisaxena/yoga-pose-image-classification-dataset). The creator of the dataset is Shruthi Saxena. The dataset comprises of 107 classes/yoga-poses and 5991 images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgQYdkw_0nhZ"
      },
      "source": [
        "**IMPORTING LIBRARIES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJHj28ubGBGn"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from tqdm import tqdm                                \n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXmWNwTmNC-E"
      },
      "source": [
        "# **LOADING THE DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSJbx0hwpEX_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "104c6776-62ea-43ac-dec2-ce7bc7fae2eb"
      },
      "source": [
        "from google.colab import drive  \n",
        "drive._mount('/content/drive') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTwX7mtSpWo8",
        "outputId": "f8d2bf4e-f0ef-4dae-bf85-8919b4a415b4"
      },
      "source": [
        "data_dir = '/content/drive/MyDrive/Colab Notebooks/Yoga_image/augged'\n",
        "labels = os.listdir(data_dir)\n",
        "for i in labels:\n",
        "  l = os.listdir(data_dir+'/'+i)\n",
        "  print(i, len(l))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hanumanasana 70\n",
            "halasana 132\n",
            "ustrasana 174\n",
            "dwi pada viparita dandasana 110\n",
            "janu sirsasana 96\n",
            "bhujangasana 146\n",
            "mayurasana 102\n",
            "dandasana 120\n",
            "simhasana 98\n",
            "bitilasana 174\n",
            "ananda balasana 118\n",
            "gomukhasana 144\n",
            "makarasana 114\n",
            "salamba sirsasana 120\n",
            "chakravakasana 140\n",
            "virabhadrasana iii 122\n",
            "parsva bakasana 112\n",
            "ganda bherundasana 78\n",
            "supta baddha konasana 142\n",
            "anjaneyasana 128\n",
            "parivrtta parsvakonasana 80\n",
            "urdhva dhanurasana 136\n",
            "eka pada koundinyanasana ii 116\n",
            "eka pada koundinyanasana i 102\n",
            "utthita trikonasana 138\n",
            "durvasasana 78\n",
            "upavistha konasana 120\n",
            "viparita karani 138\n",
            "virabhadrasana ii 111\n",
            "salamba bhujangasana 110\n",
            "yoganidrasana 92\n",
            "bharadvajasana i 108\n",
            "adho mukha svanasana 137\n",
            "eka pada rajakapotasana 88\n",
            "sukhasana 100\n",
            "matsyasana 114\n",
            "vasisthasana 148\n",
            "astavakrasana 144\n",
            "paripurna navasana 136\n",
            "marichyasana i 98\n",
            "agnistambhasana 66\n",
            "virabhadrasana i 109\n",
            "tulasana 62\n",
            "kurmasana 80\n",
            "marichyasana iii 66\n",
            "marjaryasana 92\n",
            "camatkarasana 108\n",
            "adho mukha vriksasana 118\n",
            "tolasana 120\n",
            "salamba sarvangasana 134\n",
            "parivrtta janu sirsasana 78\n",
            "salabhasana 116\n",
            "parighasana 86\n",
            "phalakasana 114\n",
            "urdhva mukha svanasana 126\n",
            "balasana 140\n",
            "virasana 100\n",
            "parsvottanasana 70\n",
            "vriksasana 124\n",
            "supta virasana 120\n",
            "chaturanga dandasana 180\n",
            "savasana 114\n",
            "ardha matsyendrasana 180\n",
            "lolasana 72\n",
            "parivrtta trikonasana 124\n",
            "padmasana 134\n",
            "urdhva hastasana 94\n",
            "dhanurasana 92\n",
            "setu bandha sarvangasana 116\n",
            "ardha pincha mayurasana 94\n",
            "natarajasana 144\n",
            "ardha uttanasana 132\n",
            "prasarita padottanasana 132\n",
            "eka pada rajakapotasana ii 110\n",
            "purvottanasana 126\n",
            "utthita hasta padangustasana 118\n",
            "bhekasana 78\n",
            "ardha chandrasana 104\n",
            "malasana 136\n",
            "kapotasana 114\n",
            "bhairavasana 92\n",
            "supta matsyendrasana 108\n",
            "uttana shishosana 100\n",
            "anantasana 86\n",
            "pincha mayurasana 70\n",
            "tittibhasana 114\n",
            "makara adho mukha svanasana 86\n",
            "ashtanga namaskara 67\n",
            "padangusthasana 36\n",
            "bhujapidasana 122\n",
            "tadasana 108\n",
            "baddha konasana 136\n",
            "urdhva prasarita eka padasana 106\n",
            "utthita ashwa sanchalanasana 76\n",
            "vrischikasana 102\n",
            "supta padangusthasana 124\n",
            "pasasana 112\n",
            "krounchasana 90\n",
            "vajrasana 108\n",
            "utthita parsvakonasana 126\n",
            "garudasana 156\n",
            "uttanasana 126\n",
            "ardha bhekasana 80\n",
            "bakasana 154\n",
            "utkatasana 146\n",
            "garbha pindasana 72\n",
            "paschimottanasana 112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEzJb5_1lfAj"
      },
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transformations = transforms.Compose([transforms.Resize((256, 256)), \n",
        "                                      transforms.RandomCrop(224),\n",
        "                                     transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "dataset = ImageFolder(data_dir, transform = transformations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUMtbivlHWX4",
        "outputId": "c2bc42d6-c8b0-4a9e-a7d9-867123c606bd"
      },
      "source": [
        "dataset.class_to_idx                                          # Shows index of each label for prediction purposes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'adho mukha svanasana': 0,\n",
              " 'adho mukha vriksasana': 1,\n",
              " 'agnistambhasana': 2,\n",
              " 'ananda balasana': 3,\n",
              " 'anantasana': 4,\n",
              " 'anjaneyasana': 5,\n",
              " 'ardha bhekasana': 6,\n",
              " 'ardha chandrasana': 7,\n",
              " 'ardha matsyendrasana': 8,\n",
              " 'ardha pincha mayurasana': 9,\n",
              " 'ardha uttanasana': 10,\n",
              " 'ashtanga namaskara': 11,\n",
              " 'astavakrasana': 12,\n",
              " 'baddha konasana': 13,\n",
              " 'bakasana': 14,\n",
              " 'balasana': 15,\n",
              " 'bhairavasana': 16,\n",
              " 'bharadvajasana i': 17,\n",
              " 'bhekasana': 18,\n",
              " 'bhujangasana': 19,\n",
              " 'bhujapidasana': 20,\n",
              " 'bitilasana': 21,\n",
              " 'camatkarasana': 22,\n",
              " 'chakravakasana': 23,\n",
              " 'chaturanga dandasana': 24,\n",
              " 'dandasana': 25,\n",
              " 'dhanurasana': 26,\n",
              " 'durvasasana': 27,\n",
              " 'dwi pada viparita dandasana': 28,\n",
              " 'eka pada koundinyanasana i': 29,\n",
              " 'eka pada koundinyanasana ii': 30,\n",
              " 'eka pada rajakapotasana': 31,\n",
              " 'eka pada rajakapotasana ii': 32,\n",
              " 'ganda bherundasana': 33,\n",
              " 'garbha pindasana': 34,\n",
              " 'garudasana': 35,\n",
              " 'gomukhasana': 36,\n",
              " 'halasana': 37,\n",
              " 'hanumanasana': 38,\n",
              " 'janu sirsasana': 39,\n",
              " 'kapotasana': 40,\n",
              " 'krounchasana': 41,\n",
              " 'kurmasana': 42,\n",
              " 'lolasana': 43,\n",
              " 'makara adho mukha svanasana': 44,\n",
              " 'makarasana': 45,\n",
              " 'malasana': 46,\n",
              " 'marichyasana i': 47,\n",
              " 'marichyasana iii': 48,\n",
              " 'marjaryasana': 49,\n",
              " 'matsyasana': 50,\n",
              " 'mayurasana': 51,\n",
              " 'natarajasana': 52,\n",
              " 'padangusthasana': 53,\n",
              " 'padmasana': 54,\n",
              " 'parighasana': 55,\n",
              " 'paripurna navasana': 56,\n",
              " 'parivrtta janu sirsasana': 57,\n",
              " 'parivrtta parsvakonasana': 58,\n",
              " 'parivrtta trikonasana': 59,\n",
              " 'parsva bakasana': 60,\n",
              " 'parsvottanasana': 61,\n",
              " 'pasasana': 62,\n",
              " 'paschimottanasana': 63,\n",
              " 'phalakasana': 64,\n",
              " 'pincha mayurasana': 65,\n",
              " 'prasarita padottanasana': 66,\n",
              " 'purvottanasana': 67,\n",
              " 'salabhasana': 68,\n",
              " 'salamba bhujangasana': 69,\n",
              " 'salamba sarvangasana': 70,\n",
              " 'salamba sirsasana': 71,\n",
              " 'savasana': 72,\n",
              " 'setu bandha sarvangasana': 73,\n",
              " 'simhasana': 74,\n",
              " 'sukhasana': 75,\n",
              " 'supta baddha konasana': 76,\n",
              " 'supta matsyendrasana': 77,\n",
              " 'supta padangusthasana': 78,\n",
              " 'supta virasana': 79,\n",
              " 'tadasana': 80,\n",
              " 'tittibhasana': 81,\n",
              " 'tolasana': 82,\n",
              " 'tulasana': 83,\n",
              " 'upavistha konasana': 84,\n",
              " 'urdhva dhanurasana': 85,\n",
              " 'urdhva hastasana': 86,\n",
              " 'urdhva mukha svanasana': 87,\n",
              " 'urdhva prasarita eka padasana': 88,\n",
              " 'ustrasana': 89,\n",
              " 'utkatasana': 90,\n",
              " 'uttana shishosana': 91,\n",
              " 'uttanasana': 92,\n",
              " 'utthita ashwa sanchalanasana': 93,\n",
              " 'utthita hasta padangustasana': 94,\n",
              " 'utthita parsvakonasana': 95,\n",
              " 'utthita trikonasana': 96,\n",
              " 'vajrasana': 97,\n",
              " 'vasisthasana': 98,\n",
              " 'viparita karani': 99,\n",
              " 'virabhadrasana i': 100,\n",
              " 'virabhadrasana ii': 101,\n",
              " 'virabhadrasana iii': 102,\n",
              " 'virasana': 103,\n",
              " 'vriksasana': 104,\n",
              " 'vrischikasana': 105,\n",
              " 'yoganidrasana': 106}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL0PE69LpBny",
        "outputId": "f0f56761-4577-4dfb-d573-36ea729144d8"
      },
      "source": [
        "targets = dataset.targets\n",
        "len(targets) # After augmentation, the size of the dataset has increased as can be seen from its output. [11899]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11901"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzphnpTtN343"
      },
      "source": [
        "# **TRAIN - TEST SPLIT**\n",
        "\n",
        "20% of the data is used for testing, while the remaining 80% is used for training. A stratified split was done so that the number of classes in training and test sets are split uniformly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwgFd6k5mLZX"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_idx, test_idx= train_test_split(np.arange(len(targets)),test_size=0.20,shuffle=True,stratify=targets) #train_idx, test_idx gives the indexes of the data in each split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AUSbQQgp84q"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(dataset, batch_size=32, sampler=train_idx)    # Based on the indexes we get after splitting in the above sets, we load the corresponding data \n",
        "testloader = torch.utils.data.DataLoader(dataset, batch_size=32, sampler=test_idx)      # into trainloader and testloader."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o79AmuOwpgYX"
      },
      "source": [
        "\n",
        "\n",
        "# **RESNET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkCy9L16Oeom"
      },
      "source": [
        "resnet = models.resnet18(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9hY1jkCPr-Q",
        "outputId": "1c09c117-6168-467a-d875-7eabbaaadf98"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_DT90TlPixK"
      },
      "source": [
        "resnet = resnet.to(device)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adagrad(resnet.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azxRtxpZS6wm"
      },
      "source": [
        "train_losses = []\n",
        "train_acc = []\n",
        "test_losses = []\n",
        "test_acc = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wW3USoqlSHRq",
        "outputId": "bfc34cd9-db25-4022-de09-77ca50258206"
      },
      "source": [
        "for epoch in range(8):   # Run for loop for number of times. The number of times is the epochs\n",
        "    train_correct = 0\n",
        "    total1 = 0\n",
        "    running_loss = 0\n",
        "    with tqdm(trainloader, unit=\"batch\") as tepoch:\n",
        "        for images, labels in tepoch:                               # Training the dataset\n",
        "            tepoch.set_description(f\"Training : Epoch {epoch+1}\")\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "            labels = labels.long()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = resnet(images) \n",
        "            loss = loss_func(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total1 += labels.size(0)\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                train_correct += (predicted.cpu() == labels.cpu()).sum().item()\n",
        "                traincorrect = (predicted.cpu() == labels.cpu()).sum().item()\n",
        "            else:\n",
        "                train_correct += (predicted == labels).sum().item()\n",
        "                traincorrect = (predicted == labels).sum().item()\n",
        "            tepoch.set_postfix(loss=loss.item(), accuracy=100* (traincorrect/32.0))\n",
        "\n",
        "    train_accuracy = 100 * train_correct / total1\n",
        "    train_loss = running_loss/len(trainloader)\n",
        "    train_acc.append(train_accuracy)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    pred = []\n",
        "    test = []\n",
        "    with tqdm(testloader, unit=\"batch\") as tstepoch:      \n",
        "        for images, labels in tstepoch:                                       # Testing \n",
        "            tstepoch.set_description(f\"Testing : Epoch {epoch+1}\")\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "            labels = labels.long() \n",
        "            outputs = resnet(images)\n",
        "            loss_t = loss_func(outputs, labels)\n",
        "            test_loss += loss_t.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            if torch.cuda.is_available():\n",
        "                correct += (predicted.cpu() == labels.cpu()).sum().item()\n",
        "                tstcorrect = (predicted.cpu() == labels.cpu()).sum().item()\n",
        "            else:\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                tstcorrect = (predicted == labels).sum().item()\n",
        "            tstepoch.set_postfix(loss=loss_t.item(), accuracy=100*(tstcorrect/32.0))\n",
        " \n",
        "    test_loss=test_loss/len(testloader)\n",
        "    accuracy = 100 * correct / total\n",
        "    test_acc.append(accuracy)\n",
        "    test_losses.append(test_loss)\n",
        "    print('\\nEpoch: {} - loss: {} - accuracy: {} - val_Loss: {} - val_accuracy: {}\\n'.format(epoch+1, train_loss, train_accuracy, test_loss, accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training : Epoch 1: 100%|██████████| 298/298 [02:44<00:00,  1.81batch/s, accuracy=3.12, loss=3.69]\n",
            "Testing : Epoch 1: 100%|██████████| 75/75 [00:32<00:00,  2.32batch/s, accuracy=0, loss=4.25]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1 - loss: 4.651851864469132 - accuracy: 3.203781512605042 - val_Loss: 4.125290314356486 - val_accuracy: 5.585888282234356\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training : Epoch 2: 100%|██████████| 298/298 [02:45<00:00,  1.80batch/s, accuracy=18.8, loss=2.49]\n",
            "Testing : Epoch 2: 100%|██████████| 75/75 [00:32<00:00,  2.30batch/s, accuracy=3.12, loss=3.16]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2 - loss: 3.417779590459478 - accuracy: 16.19747899159664 - val_Loss: 2.9291252581278484 - val_accuracy: 25.829483410331793\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training : Epoch 3: 100%|██████████| 298/298 [02:45<00:00,  1.80batch/s, accuracy=31.2, loss=1.82]\n",
            "Testing : Epoch 3: 100%|██████████| 75/75 [00:32<00:00,  2.31batch/s, accuracy=15.6, loss=2.61]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3 - loss: 2.39119498321674 - accuracy: 35.924369747899156 - val_Loss: 2.2900156736373902 - val_accuracy: 38.80722385552289\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training : Epoch 4: 100%|██████████| 298/298 [02:44<00:00,  1.81batch/s, accuracy=40.6, loss=1.02]\n",
            "Testing : Epoch 4: 100%|██████████| 75/75 [00:32<00:00,  2.32batch/s, accuracy=15.6, loss=2.18]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4 - loss: 1.661712235852376 - accuracy: 53.85504201680672 - val_Loss: 1.8769607400894166 - val_accuracy: 49.6010079798404\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training : Epoch 5: 100%|██████████| 298/298 [02:45<00:00,  1.80batch/s, accuracy=40.6, loss=0.63]\n",
            "Testing : Epoch 5: 100%|██████████| 75/75 [00:32<00:00,  2.32batch/s, accuracy=28.1, loss=1.64]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5 - loss: 1.1425085805806539 - accuracy: 67.39495798319328 - val_Loss: 1.6810058975219726 - val_accuracy: 54.85090298194036\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training : Epoch 6: 100%|██████████| 298/298 [02:45<00:00,  1.80batch/s, accuracy=46.9, loss=0.237]\n",
            "Testing : Epoch 6: 100%|██████████| 75/75 [00:32<00:00,  2.33batch/s, accuracy=18.8, loss=1.71]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 6 - loss: 0.7449280785634214 - accuracy: 79.00210084033614 - val_Loss: 1.610352461338043 - val_accuracy: 56.656866862662746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training : Epoch 7: 100%|██████████| 298/298 [02:44<00:00,  1.82batch/s, accuracy=50, loss=0.0849]\n",
            "Testing : Epoch 7: 100%|██████████| 75/75 [00:31<00:00,  2.34batch/s, accuracy=25, loss=1.57]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 7 - loss: 0.46755392839444565 - accuracy: 87.51050420168067 - val_Loss: 1.5786148182551065 - val_accuracy: 57.790844183116334\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training : Epoch 8: 100%|██████████| 298/298 [02:42<00:00,  1.83batch/s, accuracy=50, loss=0.0551]\n",
            "Testing : Epoch 8: 100%|██████████| 75/75 [00:31<00:00,  2.35batch/s, accuracy=25, loss=1.61]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 8 - loss: 0.27052286207275905 - accuracy: 93.64495798319328 - val_Loss: 1.5812443240483602 - val_accuracy: 59.68080638387232\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa4EqK6-5qBu"
      },
      "source": [
        "# **VGG**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0JWOLoAQBOH"
      },
      "source": [
        "from torchvision import models\n",
        "vgg = models.vgg16_bn()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV4rMscqQKE6",
        "outputId": "195944f4-29ee-4aa6-95bc-4631d8e44323"
      },
      "source": [
        "final_in_features = vgg.classifier[6].in_features\n",
        "mod_classifier = list(vgg.classifier.children())[:-1]\n",
        "mod_classifier.extend([nn.Linear(final_in_features, 107)])\n",
        "print(mod_classifier)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Linear(in_features=25088, out_features=4096, bias=True), ReLU(inplace=True), Dropout(p=0.5, inplace=False), Linear(in_features=4096, out_features=4096, bias=True), ReLU(inplace=True), Dropout(p=0.5, inplace=False), Linear(in_features=4096, out_features=107, bias=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yaE_A7ZQK8t"
      },
      "source": [
        "vgg.classifier = nn.Sequential(*mod_classifier)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVhONlYPQYwN"
      },
      "source": [
        "def evaluation(dataloader, model):\n",
        "    total, correct = 0, 0\n",
        "    for data in dataloader:\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (pred == labels).sum().item()\n",
        "    return 100 * correct / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbyQhv-BTwKn",
        "outputId": "986aea2e-202f-46ae-a92d-767dfec1c8f6"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVa1J-nBQZbc"
      },
      "source": [
        "vgg = vgg.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = optim.SGD(vgg.parameters(), lr=0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPmylpJq1KQE",
        "outputId": "84311599-ed5f-4003-c403-656db04f43e4"
      },
      "source": [
        "train_losses = []\n",
        "train_acc = []\n",
        "test_losses = []\n",
        "test_acc = []\n",
        "for epoch in range(8):   # Run for loop for number of times. The number of times is the epochs\n",
        "    train_correct = 0\n",
        "    total1 = 0\n",
        "    running_loss = 0\n",
        "    with tqdm(trainloader, unit=\"batch\") as tepoch:\n",
        "        for images, labels in tepoch:                               # Training the dataset\n",
        "            tepoch.set_description(f\"Training : Epoch {epoch+1}\")\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "            labels = labels.long()\n",
        "            opt.zero_grad()\n",
        "            outputs = vgg(images) \n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total1 += labels.size(0)\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                train_correct += (predicted.cpu() == labels.cpu()).sum().item()\n",
        "                traincorrect = (predicted.cpu() == labels.cpu()).sum().item()\n",
        "            else:\n",
        "                train_correct += (predicted == labels).sum().item()\n",
        "                traincorrect = (predicted == labels).sum().item()\n",
        "            tepoch.set_postfix(loss=loss.item(), accuracy=100* (traincorrect/32.0))\n",
        "\n",
        "    train_accuracy = 100 * train_correct / total1\n",
        "    train_loss = running_loss/len(trainloader)\n",
        "    train_acc.append(train_accuracy)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    pred = []\n",
        "    test = []\n",
        "    with tqdm(testloader, unit=\"batch\") as tstepoch:      \n",
        "        for images, labels in tstepoch:                                       # Testing \n",
        "            tstepoch.set_description(f\"Testing : Epoch {epoch+1}\")\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "            labels = labels.long() \n",
        "            outputs = vgg(images)\n",
        "            loss_t = loss_fn(outputs, labels)\n",
        "            test_loss += loss_t.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            if torch.cuda.is_available():\n",
        "                correct += (predicted.cpu() == labels.cpu()).sum().item()\n",
        "                tstcorrect = (predicted.cpu() == labels.cpu()).sum().item()\n",
        "            else:\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                tstcorrect = (predicted == labels).sum().item()\n",
        "            tstepoch.set_postfix(loss=loss_t.item(), accuracy=100*(tstcorrect/32.0))\n",
        " \n",
        "    test_loss=test_loss/len(testloader)\n",
        "    accuracy = 100 * correct / total\n",
        "    test_acc.append(accuracy)\n",
        "    test_losses.append(test_loss)\n",
        "    print('\\nEpoch: {} - loss: {} - accuracy: {} - val_Loss: {} - val_accuracy: {}\\n'.format(epoch+1, train_loss, train_accuracy, test_loss, accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training : Epoch 1: 100%|██████████| 298/298 [07:28<00:00,  1.50s/batch, accuracy=34.4, loss=0.99]\n",
            "Testing : Epoch 1: 100%|██████████| 75/75 [00:51<00:00,  1.45batch/s, accuracy=12.5, loss=3.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1 - loss: 1.685742678258243 - accuracy: 52.305914486815844 - val_Loss: 2.5152920802434284 - val_accuracy: 38.69747899159664\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training : Epoch 2: 100%|██████████| 298/298 [07:25<00:00,  1.50s/batch, accuracy=34.4, loss=1.2]\n",
            "Testing : Epoch 2: 100%|██████████| 75/75 [00:52<00:00,  1.44batch/s, accuracy=18.8, loss=2.66]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2 - loss: 1.5893370541150138 - accuracy: 53.93423678957874 - val_Loss: 2.3241611909866333 - val_accuracy: 41.21848739495798\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training : Epoch 3: 100%|██████████| 298/298 [07:25<00:00,  1.49s/batch, accuracy=31.2, loss=1.52]\n",
            "Testing : Epoch 3: 100%|██████████| 75/75 [00:51<00:00,  1.46batch/s, accuracy=12.5, loss=3.07]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3 - loss: 1.4835176231877116 - accuracy: 56.89673285008929 - val_Loss: 2.4465795040130613 - val_accuracy: 41.554621848739494\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training : Epoch 4: 100%|██████████| 298/298 [07:25<00:00,  1.49s/batch, accuracy=34.4, loss=0.866]\n",
            "Testing : Epoch 4: 100%|██████████| 75/75 [00:51<00:00,  1.45batch/s, accuracy=9.38, loss=3.44]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4 - loss: 1.349482390704571 - accuracy: 60.184893371152434 - val_Loss: 2.3712131945292154 - val_accuracy: 42.436974789915965\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training : Epoch 5: 100%|██████████| 298/298 [07:25<00:00,  1.49s/batch, accuracy=28.1, loss=1.08]\n",
            "Testing : Epoch 5: 100%|██████████| 75/75 [00:51<00:00,  1.45batch/s, accuracy=15.6, loss=3.17]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5 - loss: 1.3033865434211374 - accuracy: 61.056833701019016 - val_Loss: 2.303791982332865 - val_accuracy: 44.36974789915966\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training : Epoch 6: 100%|██████████| 298/298 [07:25<00:00,  1.49s/batch, accuracy=34.4, loss=0.794]\n",
            "Testing : Epoch 6: 100%|██████████| 75/75 [00:52<00:00,  1.44batch/s, accuracy=18.8, loss=2.53]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 6 - loss: 1.15396507884432 - accuracy: 65.11188150015758 - val_Loss: 2.348325098355611 - val_accuracy: 45.79831932773109\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training : Epoch 7: 100%|██████████| 298/298 [07:27<00:00,  1.50s/batch, accuracy=34.4, loss=0.757]\n",
            "Testing : Epoch 7: 100%|██████████| 75/75 [00:52<00:00,  1.44batch/s, accuracy=12.5, loss=2.93]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 7 - loss: 1.099222873081297 - accuracy: 66.80323563399517 - val_Loss: 2.279411981900533 - val_accuracy: 45.08403361344538\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training : Epoch 8: 100%|██████████| 298/298 [07:28<00:00,  1.50s/batch, accuracy=34.4, loss=0.757]\n",
            "Testing : Epoch 8: 100%|██████████| 75/75 [00:52<00:00,  1.44batch/s, accuracy=9.38, loss=3.32]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 8 - loss: 1.035849339709986 - accuracy: 68.02185103477257 - val_Loss: 2.2568754291534425 - val_accuracy: 46.30252100840336\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv9vVOWu5uCp"
      },
      "source": [
        "# **MOBILE NET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOYySRYymhXD"
      },
      "source": [
        "mobNet = models.mobilenet_v2(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGdjG-17m938"
      },
      "source": [
        "mobNet.classifier[-1].out_features = 107"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAi7Qffqnv2t",
        "outputId": "c9df98cd-c8ee-431b-d67e-c6c96346804a"
      },
      "source": [
        "mobNet.classifier[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=1280, out_features=107, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFIfJBxIvpRq"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Obvs7fyQuffn"
      },
      "source": [
        "mobNet = mobNet.to('cuda')    # Load the model to GPU."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-a0_aHyutXO"
      },
      "source": [
        "optimizer = optim.Adadelta(mobNet.parameters())     # Defining the optimiser.\n",
        "loss_func = nn.CrossEntropyLoss()                            # Defining the loss function\n",
        "                                                    # Vary optimiser and loss function as per requirement while training."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76zab8RO6f2N",
        "outputId": "ac5a87a8-e9d3-4a47-bfa7-ee3274225b89"
      },
      "source": [
        "train_losses = []\n",
        "train_acc = []\n",
        "test_losses = []\n",
        "test_acc = []\n",
        "for epoch in range(10):   # Run for loop for number of times. The number of times is the epochs\n",
        "    train_correct = 0\n",
        "    total1 = 0\n",
        "    running_loss = 0\n",
        "    with tqdm(trainloader, unit=\"batch\") as tepoch:\n",
        "        for images, labels in tepoch:                               # Training the dataset\n",
        "            tepoch.set_description(f\"Training : Epoch {epoch+1}\")\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "            labels = labels.long()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = mobNet(images) \n",
        "            loss = loss_func(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total1 += labels.size(0)\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                train_correct += (predicted.cpu() == labels.cpu()).sum().item()\n",
        "                traincorrect = (predicted.cpu() == labels.cpu()).sum().item()\n",
        "            else:\n",
        "                train_correct += (predicted == labels).sum().item()\n",
        "                traincorrect = (predicted == labels).sum().item()\n",
        "            tepoch.set_postfix(loss=loss.item(), accuracy=100* (traincorrect/32.0))\n",
        "\n",
        "    train_accuracy = 100 * train_correct / total1\n",
        "    train_loss = running_loss/len(trainloader)\n",
        "    train_acc.append(train_accuracy)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    pred = []\n",
        "    test = []\n",
        "    with tqdm(testloader, unit=\"batch\") as tstepoch:      \n",
        "        for images, labels in tstepoch:                                       # Testing \n",
        "            tstepoch.set_description(f\"Testing : Epoch {epoch+1}\")\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "            labels = labels.long() \n",
        "            outputs = mobNet(images)\n",
        "            loss_t = loss_func(outputs, labels)\n",
        "            test_loss += loss_t.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            if torch.cuda.is_available():\n",
        "                correct += (predicted.cpu() == labels.cpu()).sum().item()\n",
        "                tstcorrect = (predicted.cpu() == labels.cpu()).sum().item()\n",
        "            else:\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                tstcorrect = (predicted == labels).sum().item()\n",
        "            tstepoch.set_postfix(loss=loss_t.item(), accuracy=100*(tstcorrect/32.0))\n",
        " \n",
        "    test_loss=test_loss/len(testloader)\n",
        "    accuracy = 100 * correct / total\n",
        "    test_acc.append(accuracy)\n",
        "    test_losses.append(test_loss)\n",
        "    print('\\nEpoch: {} - loss: {} - accuracy: {} - val_Loss: {} - val_accuracy: {}\\n'.format(epoch+1, train_loss, train_accuracy, test_loss, accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training : Epoch 1: 100%|██████████| 298/298 [31:21<00:00,  6.31s/batch, accuracy=18.8, loss=2.88]\n",
            "Testing : Epoch 1: 100%|██████████| 75/75 [07:42<00:00,  6.16s/batch, accuracy=0, loss=3.36]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1 - loss: 3.8816117800322156 - accuracy: 13.803971005357706 - val_Loss: 3.0033382511138917 - val_accuracy: 24.07563025210084\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training : Epoch 2: 100%|██████████| 298/298 [03:07<00:00,  1.59batch/s, accuracy=18.8, loss=2.79]\n",
            "Testing : Epoch 2: 100%|██████████| 75/75 [00:34<00:00,  2.19batch/s, accuracy=9.38, loss=3.13]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 2 - loss: 2.4884316837227582 - accuracy: 34.14224183212522 - val_Loss: 2.5727002255121865 - val_accuracy: 34.95798319327731\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training : Epoch 3: 100%|██████████| 298/298 [03:02<00:00,  1.63batch/s, accuracy=18.8, loss=1.73]\n",
            "Testing : Epoch 3: 100%|██████████| 75/75 [00:32<00:00,  2.34batch/s, accuracy=9.38, loss=2.7]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 3 - loss: 1.9872124607130985 - accuracy: 45.19382288055468 - val_Loss: 2.260815477371216 - val_accuracy: 41.890756302521005\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training : Epoch 4: 100%|██████████| 298/298 [02:59<00:00,  1.66batch/s, accuracy=25, loss=1.56]\n",
            "Testing : Epoch 4: 100%|██████████| 75/75 [00:31<00:00,  2.36batch/s, accuracy=9.38, loss=2.67]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 4 - loss: 1.7056690602494566 - accuracy: 52.42147284378611 - val_Loss: 2.09018141746521 - val_accuracy: 45.84033613445378\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training : Epoch 5: 100%|██████████| 298/298 [02:58<00:00,  1.67batch/s, accuracy=28.1, loss=1.19]\n",
            "Testing : Epoch 5: 100%|██████████| 75/75 [00:32<00:00,  2.34batch/s, accuracy=15.6, loss=2.39]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 5 - loss: 1.4896685517074277 - accuracy: 57.81069440067234 - val_Loss: 1.9469972705841065 - val_accuracy: 48.90756302521008\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training : Epoch 6: 100%|██████████| 298/298 [03:02<00:00,  1.63batch/s, accuracy=34.4, loss=0.893]\n",
            "Testing : Epoch 6: 100%|██████████| 75/75 [00:32<00:00,  2.32batch/s, accuracy=12.5, loss=2.29]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 6 - loss: 1.3383480506455339 - accuracy: 60.37398886437651 - val_Loss: 1.8099801858266196 - val_accuracy: 53.02521008403362\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training : Epoch 7: 100%|██████████| 298/298 [03:00<00:00,  1.65batch/s, accuracy=40.6, loss=0.558]\n",
            "Testing : Epoch 7: 100%|██████████| 75/75 [00:32<00:00,  2.32batch/s, accuracy=15.6, loss=1.74]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 7 - loss: 1.2252313600690572 - accuracy: 64.00882445635045 - val_Loss: 1.8144404888153076 - val_accuracy: 53.36134453781513\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training : Epoch 8: 100%|██████████| 298/298 [02:58<00:00,  1.67batch/s, accuracy=34.4, loss=0.681]\n",
            "Testing : Epoch 8: 100%|██████████| 75/75 [00:31<00:00,  2.38batch/s, accuracy=9.38, loss=2.34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 8 - loss: 1.1323811785886753 - accuracy: 67.03435234793571 - val_Loss: 1.7036404911677043 - val_accuracy: 55.46218487394958\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training : Epoch 9: 100%|██████████| 298/298 [02:59<00:00,  1.66batch/s, accuracy=37.5, loss=0.54]\n",
            "Testing : Epoch 9: 100%|██████████| 75/75 [00:32<00:00,  2.28batch/s, accuracy=15.6, loss=3.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 9 - loss: 1.0451367997483119 - accuracy: 68.77823300766887 - val_Loss: 1.7924599854151408 - val_accuracy: 55.54621848739496\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training : Epoch 10: 100%|██████████| 298/298 [03:04<00:00,  1.61batch/s, accuracy=37.5, loss=0.641]\n",
            "Testing : Epoch 10: 100%|██████████| 75/75 [00:33<00:00,  2.26batch/s, accuracy=18.8, loss=1.63]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 10 - loss: 0.9687209528364591 - accuracy: 70.59565080365584 - val_Loss: 1.718844230969747 - val_accuracy: 54.411764705882355\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}